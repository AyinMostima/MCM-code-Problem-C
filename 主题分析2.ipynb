{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer,tokenizer_from_json\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import json\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "embedding_dim=100\n",
    "oov_token = '<OOV>'\n",
    "train_test_split = 0.8\n",
    "max_len = 200\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../DBPEDIA_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "labels = df.get('l1').values.tolist()\n",
    "articles = df.get('text').values.tolist()\n",
    "for i in range(len(articles)):\n",
    "    for word in STOPWORDS:\n",
    "        token = ' '+word+' '\n",
    "        articles[i] = articles[i].replace(token,' ')\n",
    "        articles[i] = re.sub(r'\\s+', ' ',articles[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(articles)\n",
    "sequences = tokenizer.texts_to_sequences(articles)\n",
    "article_sequences = pad_sequences(sequences,maxlen=max_len,truncating=trunc_type,padding=padding_type)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index)\n",
    "\n",
    "split_index = int(len(article_sequences)*train_test_split)\n",
    "train_sequences = np.array(article_sequences[0:split_index])\n",
    "test_sequences = np.array(article_sequences[split_index:])\n",
    "\n",
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(labels)\n",
    "label_sequences = label_tokenizer.texts_to_sequences(labels)\n",
    "train_label = np.array(label_sequences[0:split_index])\n",
    "test_label = np.array(label_sequences[split_index:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tokenizer_json = tokenizer.to_json()\n",
    "label_tokenizer_json = label_tokenizer.to_json()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "embeddings_index = {};\n",
    "with open('../../glove.6B.100d.txt',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split();\n",
    "        word = values[0];\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs;\n",
    "\n",
    "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embeddings_matrix[i] = embedding_vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "if not os.path.exists('tokenizer.json'):\n",
    "    with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "if not os.path.exists('label_tokenizer_json.json'):\n",
    "    with open('label_tokenizer_json.json', 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(label_tokenizer_json, ensure_ascii=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "np.save('train_sequences.npy',train_sequences)\n",
    "np.save('train_label.npy',train_label)\n",
    "np.save('test_sequences.npy',test_sequences)\n",
    "np.save('test_label.npy',test_label)\n",
    "np.save('embeddings_matrix.npy',embeddings_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48635, 200)\n",
      "(48635, 1)\n",
      "(12159, 200)\n",
      "(12159, 1)\n",
      "226516\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences.shape)\n",
    "print(train_label.shape)\n",
    "print(test_sequences.shape)\n",
    "print(test_label.shape)\n",
    "print(vocab_size)\n",
    "print(word_index['i'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, LSTM, Embedding,Conv2D,Bidirectional,MaxPool2D,Reshape\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer,tokenizer_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import json\n",
    "import os\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "with open('tokenizer.json', 'r', encoding='utf-8') as f1:\n",
    "    tokenizer_config = json.load(f1)\n",
    "with open('label_tokenizer_json.json', 'r', encoding='utf-8') as f2:\n",
    "    label_tokenizer_config = json.load(f2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_sequences= np.load('train_sequences.npy')\n",
    "train_label= np.load('train_label.npy')\n",
    "test_sequences = np.load('test_sequences.npy')\n",
    "test_label= np.load('test_label.npy')\n",
    "embeddings_matrix= np.load('embeddings_matrix.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_3752\\3165034312.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtokenizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtokenizer_from_json\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtokenizer_config\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mlabel_tokenizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtokenizer_from_json\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabel_tokenizer_config\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tokenizer_config' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_from_json(tokenizer_config)\n",
    "label_tokenizer = tokenizer_from_json(label_tokenizer_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "word_index = word_index\n",
    "vocab_size = vocab_size\n",
    "max_len = 200\n",
    "rnn_units = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 100)          22651700  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200, 100)          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200, 100)         160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200, 100)          0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 200, 100, 1)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 198, 98, 64)       640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 99, 49, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 99, 49, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 310464)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                3104650   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,917,790\n",
      "Trainable params: 3,266,090\n",
      "Non-trainable params: 22,651,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1,embedding_dim,input_length=max_len,weights=[embeddings_matrix], trainable=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(rnn_units,return_sequences=True),merge_mode='sum'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Reshape((-1,rnn_units,1)))\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adadelta',metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1520/1520 [==============================] - 724s 473ms/step - loss: 1.5630 - accuracy: 0.5165 - val_loss: 1.4191 - val_accuracy: 0.5139\n",
      "Epoch 2/10\n",
      "1520/1520 [==============================] - 702s 462ms/step - loss: 1.3353 - accuracy: 0.5253 - val_loss: 1.2694 - val_accuracy: 0.5581\n",
      "Epoch 3/10\n",
      "1520/1520 [==============================] - 730s 480ms/step - loss: 1.2093 - accuracy: 0.5682 - val_loss: 1.1202 - val_accuracy: 0.6058\n",
      "Epoch 4/10\n",
      "1520/1520 [==============================] - 666s 438ms/step - loss: 1.0818 - accuracy: 0.6153 - val_loss: 0.9810 - val_accuracy: 0.6803\n",
      "Epoch 5/10\n",
      "1520/1520 [==============================] - 684s 450ms/step - loss: 0.9658 - accuracy: 0.6774 - val_loss: 0.8671 - val_accuracy: 0.7321\n",
      "Epoch 6/10\n",
      "1520/1520 [==============================] - 758s 499ms/step - loss: 0.8676 - accuracy: 0.7227 - val_loss: 0.7705 - val_accuracy: 0.7641\n",
      "Epoch 7/10\n",
      "1520/1520 [==============================] - 632s 416ms/step - loss: 0.7854 - accuracy: 0.7504 - val_loss: 0.6936 - val_accuracy: 0.7875\n",
      "Epoch 8/10\n",
      "1520/1520 [==============================] - 674s 444ms/step - loss: 0.7190 - accuracy: 0.7721 - val_loss: 0.6363 - val_accuracy: 0.8080\n",
      "Epoch 9/10\n",
      "1520/1520 [==============================] - 488s 321ms/step - loss: 0.6671 - accuracy: 0.7875 - val_loss: 0.5871 - val_accuracy: 0.8196\n",
      "Epoch 10/10\n",
      "1520/1520 [==============================] - 497s 327ms/step - loss: 0.6225 - accuracy: 0.8017 - val_loss: 0.5463 - val_accuracy: 0.8306\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2730e2c1550>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "save_dir = './saved_model'\n",
    "save_fname = os.path.join(save_dir, \"情感2.h5\")\n",
    "callbacks = [ModelCheckpoint(filepath=save_fname, monitor='loss', save_best_only=True)]\n",
    "model.fit(train_sequences,train_label,epochs=epochs,validation_data=(test_sequences,test_label),callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1520/1520 [==============================] - 660s 434ms/step - loss: 0.5859 - accuracy: 0.8125 - val_loss: 0.5143 - val_accuracy: 0.8419\n",
      "Epoch 2/10\n",
      "1520/1520 [==============================] - 603s 396ms/step - loss: 0.5556 - accuracy: 0.8219 - val_loss: 0.4875 - val_accuracy: 0.8500\n",
      "Epoch 3/10\n",
      "1520/1520 [==============================] - 638s 420ms/step - loss: 0.5273 - accuracy: 0.8310 - val_loss: 0.4604 - val_accuracy: 0.8581\n",
      "Epoch 4/10\n",
      "1520/1520 [==============================] - 620s 408ms/step - loss: 0.5023 - accuracy: 0.8390 - val_loss: 0.4383 - val_accuracy: 0.8636\n",
      "Epoch 5/10\n",
      "1520/1520 [==============================] - 475s 312ms/step - loss: 0.4816 - accuracy: 0.8439 - val_loss: 0.4196 - val_accuracy: 0.8698\n",
      "Epoch 6/10\n",
      "1520/1520 [==============================] - 481s 317ms/step - loss: 0.4618 - accuracy: 0.8517 - val_loss: 0.4001 - val_accuracy: 0.8756\n",
      "Epoch 7/10\n",
      "1520/1520 [==============================] - 637s 419ms/step - loss: 0.4449 - accuracy: 0.8558 - val_loss: 0.3857 - val_accuracy: 0.8793\n",
      "Epoch 8/10\n",
      "1520/1520 [==============================] - 635s 418ms/step - loss: 0.4294 - accuracy: 0.8604 - val_loss: 0.3704 - val_accuracy: 0.8838\n",
      "Epoch 9/10\n",
      "1520/1520 [==============================] - 487s 321ms/step - loss: 0.4146 - accuracy: 0.8650 - val_loss: 0.3579 - val_accuracy: 0.8865\n",
      "Epoch 10/10\n",
      "1520/1520 [==============================] - 488s 321ms/step - loss: 0.4027 - accuracy: 0.8673 - val_loss: 0.3441 - val_accuracy: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1d9bd34c2b0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "save_dir = './saved_model'\n",
    "save_fname = os.path.join(save_dir, \"情感2.h5\")\n",
    "callbacks = [ModelCheckpoint(filepath=save_fname, monitor='loss', save_best_only=True)]\n",
    "model.fit(train_sequences,train_label,epochs=epochs,validation_data=(test_sequences,test_label),callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1520/1520 [==============================] - 673s 443ms/step - loss: 0.3880 - accuracy: 0.8713 - val_loss: 0.3340 - val_accuracy: 0.8925\n",
      "Epoch 2/10\n",
      "1520/1520 [==============================] - 620s 408ms/step - loss: 0.3764 - accuracy: 0.8754 - val_loss: 0.3240 - val_accuracy: 0.8956\n",
      "Epoch 3/10\n",
      "1520/1520 [==============================] - 491s 323ms/step - loss: 0.3687 - accuracy: 0.8778 - val_loss: 0.3126 - val_accuracy: 0.9003\n",
      "Epoch 4/10\n",
      "1520/1520 [==============================] - 488s 321ms/step - loss: 0.3585 - accuracy: 0.8794 - val_loss: 0.3036 - val_accuracy: 0.9034\n",
      "Epoch 5/10\n",
      "1520/1520 [==============================] - 496s 326ms/step - loss: 0.3504 - accuracy: 0.8834 - val_loss: 0.2962 - val_accuracy: 0.9057\n",
      "Epoch 6/10\n",
      "1520/1520 [==============================] - 494s 325ms/step - loss: 0.3406 - accuracy: 0.8871 - val_loss: 0.2874 - val_accuracy: 0.9082\n",
      "Epoch 7/10\n",
      "1520/1520 [==============================] - 488s 321ms/step - loss: 0.3314 - accuracy: 0.8904 - val_loss: 0.2807 - val_accuracy: 0.9104\n",
      "Epoch 8/10\n",
      "1520/1520 [==============================] - 480s 316ms/step - loss: 0.3250 - accuracy: 0.8909 - val_loss: 0.2736 - val_accuracy: 0.9123\n",
      "Epoch 9/10\n",
      "1520/1520 [==============================] - 483s 318ms/step - loss: 0.3181 - accuracy: 0.8940 - val_loss: 0.2655 - val_accuracy: 0.9145\n",
      "Epoch 10/10\n",
      "1520/1520 [==============================] - 496s 326ms/step - loss: 0.3128 - accuracy: 0.8947 - val_loss: 0.2627 - val_accuracy: 0.9158\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1d9c2f42f70>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sequences,train_label,epochs=epochs,validation_data=(test_sequences,test_label),callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_6504\\533770614.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m   \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[0mplot_graphs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"accuracy\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[0mplot_graphs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"loss\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m;\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_6504\\533770614.py\u001B[0m in \u001B[0;36mplot_graphs\u001B[1;34m(history, string)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mplot_graphs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstring\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m   \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mstring\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m   \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'val_'\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mstring\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m   \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxlabel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Epochs\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "history = model.history\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\");"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
    "\n",
    "model = load_model('./saved_model/情感2.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\bidirectional\n",
      "......vars\n",
      "...layers\\bidirectional\\backward_layer\n",
      "......vars\n",
      "...layers\\bidirectional\\backward_layer\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\bidirectional\\forward_layer\n",
      "......vars\n",
      "...layers\\bidirectional\\forward_layer\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\bidirectional\\layer\n",
      "......vars\n",
      "...layers\\bidirectional\\layer\\cell\n",
      "......vars\n",
      "...layers\\conv2d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\max_pooling2d\n",
      "......vars\n",
      "...layers\\reshape\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-02-19 12:59:20         4620\n",
      "metadata.json                                  2023-02-19 12:59:20           64\n",
      "variables.h5                                   2023-02-19 12:59:21    129850952\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_3752\\1602562187.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mjoblib\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mjoblib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m\"主题分析.pkl\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mjoblib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m\"history主题分析.pkl\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model,\"主题分析.pkl\")\n",
    "joblib.dump(history,\"history主题分析.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}