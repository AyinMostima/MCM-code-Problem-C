{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from simulations import  *\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.preprocessing.text import Tokenizer,tokenizer_from_json\n",
    "from keras.utils import pad_sequences\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 处理训练集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "          Date  Contest number   Word  Number of reported results  \\\n0   2022-01-07             202  slump                       80630   \n1   2022-01-08             203  crank                      101503   \n2   2022-01-09             204  gorge                       91477   \n3   2022-01-10             205  query                      107134   \n4   2022-01-11             206  drink                      153880   \n..         ...             ...    ...                         ...   \n354 2022-12-27             556  condo                       20879   \n355 2022-12-28             557  impel                       20160   \n356 2022-12-29             558  havoc                       20001   \n357 2022-12-30             559  molar                       21204   \n358 2022-12-31             560  manly                       20380   \n\n     Number in hard mode  1 Try  2 Tries  3 Tries  4 Tries  5 Tries  6 Tries  \\\n0                   1362   0.01     0.03     0.23     0.39     0.24     0.09   \n1                   1763   0.01     0.05     0.23     0.31     0.24     0.14   \n2                   1913   0.01     0.03     0.13     0.27     0.30     0.22   \n3                   2242   0.01     0.04     0.16     0.30     0.30     0.17   \n4                   3017   0.01     0.09     0.35     0.34     0.16     0.05   \n..                   ...    ...      ...      ...      ...      ...      ...   \n354                 2012   0.00     0.02     0.17     0.35     0.29     0.14   \n355                 1937   0.00     0.03     0.21     0.40     0.25     0.09   \n356                 1919   0.00     0.02     0.16     0.38     0.30     0.12   \n357                 1973   0.00     0.04     0.21     0.38     0.26     0.09   \n358                 1899   0.00     0.02     0.17     0.37     0.29     0.12   \n\n     Above 6 Tries  \n0             0.01  \n1             0.02  \n2             0.04  \n3             0.02  \n4             0.01  \n..             ...  \n354           0.03  \n355           0.01  \n356           0.02  \n357           0.01  \n358           0.02  \n\n[359 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Contest number</th>\n      <th>Word</th>\n      <th>Number of reported results</th>\n      <th>Number in hard mode</th>\n      <th>1 Try</th>\n      <th>2 Tries</th>\n      <th>3 Tries</th>\n      <th>4 Tries</th>\n      <th>5 Tries</th>\n      <th>6 Tries</th>\n      <th>Above 6 Tries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-01-07</td>\n      <td>202</td>\n      <td>slump</td>\n      <td>80630</td>\n      <td>1362</td>\n      <td>0.01</td>\n      <td>0.03</td>\n      <td>0.23</td>\n      <td>0.39</td>\n      <td>0.24</td>\n      <td>0.09</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-01-08</td>\n      <td>203</td>\n      <td>crank</td>\n      <td>101503</td>\n      <td>1763</td>\n      <td>0.01</td>\n      <td>0.05</td>\n      <td>0.23</td>\n      <td>0.31</td>\n      <td>0.24</td>\n      <td>0.14</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-01-09</td>\n      <td>204</td>\n      <td>gorge</td>\n      <td>91477</td>\n      <td>1913</td>\n      <td>0.01</td>\n      <td>0.03</td>\n      <td>0.13</td>\n      <td>0.27</td>\n      <td>0.30</td>\n      <td>0.22</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-01-10</td>\n      <td>205</td>\n      <td>query</td>\n      <td>107134</td>\n      <td>2242</td>\n      <td>0.01</td>\n      <td>0.04</td>\n      <td>0.16</td>\n      <td>0.30</td>\n      <td>0.30</td>\n      <td>0.17</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-01-11</td>\n      <td>206</td>\n      <td>drink</td>\n      <td>153880</td>\n      <td>3017</td>\n      <td>0.01</td>\n      <td>0.09</td>\n      <td>0.35</td>\n      <td>0.34</td>\n      <td>0.16</td>\n      <td>0.05</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>354</th>\n      <td>2022-12-27</td>\n      <td>556</td>\n      <td>condo</td>\n      <td>20879</td>\n      <td>2012</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.17</td>\n      <td>0.35</td>\n      <td>0.29</td>\n      <td>0.14</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>355</th>\n      <td>2022-12-28</td>\n      <td>557</td>\n      <td>impel</td>\n      <td>20160</td>\n      <td>1937</td>\n      <td>0.00</td>\n      <td>0.03</td>\n      <td>0.21</td>\n      <td>0.40</td>\n      <td>0.25</td>\n      <td>0.09</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>356</th>\n      <td>2022-12-29</td>\n      <td>558</td>\n      <td>havoc</td>\n      <td>20001</td>\n      <td>1919</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.16</td>\n      <td>0.38</td>\n      <td>0.30</td>\n      <td>0.12</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>357</th>\n      <td>2022-12-30</td>\n      <td>559</td>\n      <td>molar</td>\n      <td>21204</td>\n      <td>1973</td>\n      <td>0.00</td>\n      <td>0.04</td>\n      <td>0.21</td>\n      <td>0.38</td>\n      <td>0.26</td>\n      <td>0.09</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>358</th>\n      <td>2022-12-31</td>\n      <td>560</td>\n      <td>manly</td>\n      <td>20380</td>\n      <td>1899</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.17</td>\n      <td>0.37</td>\n      <td>0.29</td>\n      <td>0.12</td>\n      <td>0.02</td>\n    </tr>\n  </tbody>\n</table>\n<p>359 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel(\"Problem_C_Data_Wordle.xlsx\")\n",
    "data=data.sort_values(by=\"Date\")\n",
    "data=data.reset_index().drop(columns=\"index\")\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "possible_words=data[\"Word\"].to_csv(\"data/possible_words.txt\",header=False,index=False)\n",
    "optimalstart=[\"salet\",\"reast\",\"crate\",\"trace\",\"slate\",\"crane\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# # joblib.dump(resultall,\"resultall.pkl\")\n",
    "# resultall=joblib.load(\"resultall.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def dataprocess(resultall,data):\n",
    "    guesschainall=[]\n",
    "    for q,k in enumerate(optimalstart):\n",
    "        guesschain=[]\n",
    "        for i in resultall[q]['game_results']:\n",
    "            chain=i[\"guesses\"]\n",
    "            chain.append(i[\"answer\"])\n",
    "            guesschain.append(\" \".join(chain))\n",
    "        guesschainall.append(guesschain)\n",
    "\n",
    "    reductionsall=[]\n",
    "    for q,k in enumerate(optimalstart):\n",
    "        reductions=[]\n",
    "        for i in resultall[q]['game_results']:\n",
    "            reductions.append(np.sum(i[\"reductions\"]))\n",
    "        reductionsall.append(reductions)\n",
    "\n",
    "    scoresall=[]\n",
    "    for q,k in enumerate(optimalstart):\n",
    "        scores=[]\n",
    "        for i in resultall[q]['game_results']:\n",
    "            scores.append(i[\"score\"])\n",
    "        scoresall.append(scores)\n",
    "\n",
    "\n",
    "    datainner=pd.DataFrame()\n",
    "    datainner[\"Word\"]=data[\"Word\"].copy()\n",
    "    for q,k in enumerate(optimalstart):\n",
    "        datainner[k+\" guesschain\"]=guesschainall[q]\n",
    "        datainner[k+\" reductions\"]=reductionsall[q]\n",
    "        datainner[k+\" score\"]=scoresall[q]\n",
    "    dataouter=pd.DataFrame()\n",
    "    dataouter[\"Word\"]=data[\"Word\"].copy()\n",
    "    RepeatN=[]\n",
    "    for s in dataouter[\"Word\"].values:\n",
    "        RepeatN.append(len(s)-len(set(s)))\n",
    "    dataouter[\"RepeatN\"]=RepeatN\n",
    "    WordCharacterall=nltk.pos_tag(data[\"Word\"])\n",
    "    WordCharacter=[]\n",
    "    for s in WordCharacterall:\n",
    "        WordCharacter.append(s[1])\n",
    "    dataouter[\"WordCharacter\"]=WordCharacter\n",
    "\n",
    "    model = load_model('F:\\\\作业文件\\\\2023数学建模\\\\代码\\\\modeltrain\\\\主题分析\\\\saved_model\\\\情感2.h5')\n",
    "    with open('F:\\\\作业文件\\\\2023数学建模\\\\代码\\\\modeltrain\\\\主题分析\\\\tokenizer.json', 'r', encoding='utf-8') as f1:\n",
    "        tokenizer_config = json.load(f1)\n",
    "    with open('F:\\\\作业文件\\\\2023数学建模\\\\代码\\\\modeltrain\\\\主题分析\\\\label_tokenizer_json.json', 'r', encoding='utf-8') as f2:\n",
    "        label_tokenizer_config = json.load(f2)\n",
    "    tokenizer = tokenizer_from_json(tokenizer_config)\n",
    "    label_tokenizer = tokenizer_from_json(label_tokenizer_config)\n",
    "    trunc_type = 'post'\n",
    "    padding_type = 'post'\n",
    "    max_len = 200\n",
    "    for i in optimalstart:\n",
    "        seq = np.array(pad_sequences(tokenizer.texts_to_sequences(datainner[i+\" guesschain\"]),truncating=trunc_type,padding=padding_type,maxlen=max_len))\n",
    "        result = np.argmax(model.predict(seq),axis=1)[:,None].tolist()\n",
    "        dataouter[i+\" Topics\"]=label_tokenizer.sequences_to_texts(result)\n",
    "    model = load_model('F:\\\\作业文件\\\\2023数学建模\\\\代码\\\\modeltrain\\\\新闻主题分析\\\\saved_model\\\\情感2.h5')\n",
    "    with open('F:\\\\作业文件\\\\2023数学建模\\\\代码\\\\modeltrain\\\\新闻主题分析\\\\tokenizer.json', 'r', encoding='utf-8') as f1:\n",
    "        tokenizer_config = json.load(f1)\n",
    "    with open('F:\\\\作业文件\\\\2023数学建模\\\\代码\\\\modeltrain\\\\新闻主题分析\\\\label_tokenizer_json.json', 'r', encoding='utf-8') as f2:\n",
    "        label_tokenizer_config = json.load(f2)\n",
    "    tokenizer = tokenizer_from_json(tokenizer_config)\n",
    "    label_tokenizer = tokenizer_from_json(label_tokenizer_config)\n",
    "    trunc_type = 'post'\n",
    "    padding_type = 'post'\n",
    "    max_len = 200\n",
    "    for i in optimalstart:\n",
    "        seq = np.array(pad_sequences(tokenizer.texts_to_sequences(datainner[i+\" guesschain\"]),truncating=trunc_type,padding=padding_type,maxlen=max_len))\n",
    "        result = np.argmax(model.predict(seq),axis=1)[:,None].tolist()\n",
    "        dataouter[i+\" Description\"]=label_tokenizer.sequences_to_texts(result)\n",
    "    model = load_model('F:\\\\作业文件\\\\2023数学建模\\\\代码\\\\modeltrain\\\\正负情感分析\\\\saved_model\\\\情感2.h5')\n",
    "    with open('F:\\\\作业文件\\\\2023数学建模\\\\代码\\\\modeltrain\\\\正负情感分析\\\\tokenizer.json', 'r', encoding='utf-8') as f1:\n",
    "        tokenizer_config = json.load(f1)\n",
    "    with open('F:\\\\作业文件\\\\2023数学建模\\\\代码\\\\modeltrain\\\\正负情感分析\\\\label_tokenizer_json.json', 'r', encoding='utf-8') as f2:\n",
    "        label_tokenizer_config = json.load(f2)\n",
    "    tokenizer = tokenizer_from_json(tokenizer_config)\n",
    "    label_tokenizer = tokenizer_from_json(label_tokenizer_config)\n",
    "    trunc_type = 'post'\n",
    "    padding_type = 'post'\n",
    "    max_len = 200\n",
    "    for i in optimalstart:\n",
    "        seq = np.array(pad_sequences(tokenizer.texts_to_sequences(datainner[i+\" guesschain\"]),truncating=trunc_type,padding=padding_type,maxlen=max_len))\n",
    "        dataouter[i+\" Attitude\"]=model.predict(seq)[:,1]\n",
    "\n",
    "    Word5 = data[\"Word\"].apply(func = list)\n",
    "    dfword = pd.DataFrame(data = [ii for ii in Word5.values],\n",
    "                      columns=[\"word1\",\"word2\",\"word3\",\"word4\",\"word5\"])\n",
    "    datainner=datainner.join(dfword)\n",
    "    return datainner,dataouter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resultall=[]\n",
    "for i in optimalstart:\n",
    "    first_guess=i\n",
    "    results, decision_map = simulate_games(\n",
    "            first_guess=first_guess,\n",
    "            priors=get_true_wordle_prior(),\n",
    "            optimize_for_uniform_distribution=True,results_file=\"test.json\",next_guess_map_file=\"test2.json\",\n",
    "            # shuffle=True,\n",
    "            # brute_force_optimize=True,\n",
    "            hard_mode=True\n",
    "        )\n",
    "    resultall.append(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 72ms/step\n",
      "12/12 [==============================] - 1s 59ms/step\n",
      "12/12 [==============================] - 1s 58ms/step\n",
      "12/12 [==============================] - 1s 59ms/step\n",
      "12/12 [==============================] - 1s 60ms/step\n",
      "12/12 [==============================] - 1s 62ms/step\n",
      "12/12 [==============================] - 1s 61ms/step\n",
      "12/12 [==============================] - 1s 60ms/step\n",
      "12/12 [==============================] - 1s 62ms/step\n",
      "12/12 [==============================] - 1s 58ms/step\n",
      "12/12 [==============================] - 1s 74ms/step\n",
      "12/12 [==============================] - 1s 66ms/step\n",
      "12/12 [==============================] - 1s 61ms/step\n",
      "12/12 [==============================] - 1s 64ms/step\n",
      "12/12 [==============================] - 1s 61ms/step\n",
      "12/12 [==============================] - 1s 62ms/step\n",
      "12/12 [==============================] - 1s 59ms/step\n",
      "12/12 [==============================] - 1s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "datainner,dataouter=dataprocess(resultall,data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "datainner.to_csv(\"datainner.csv\")\n",
    "dataouter.to_csv(\"dataouter.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"Problem_C_Data_Wordle_test.xlsx\")\n",
    "data=data.sort_values(by=\"Date\")\n",
    "data=data.reset_index().drop(columns=\"index\")\n",
    "possible_words=data[\"Word\"].to_csv(\"data/possible_words.txt\",header=False,index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resultall=[]\n",
    "for i in optimalstart:\n",
    "    first_guess=i\n",
    "    results, decision_map = simulate_games(\n",
    "            first_guess=first_guess,\n",
    "            priors=get_true_wordle_prior(),\n",
    "            optimize_for_uniform_distribution=True,results_file=\"test.json\",next_guess_map_file=\"test2.json\",\n",
    "            # shuffle=True,\n",
    "            # brute_force_optimize=True,\n",
    "            hard_mode=True\n",
    "        )\n",
    "    resultall.append(results)\n",
    "datainner,dataouter=dataprocess(resultall,data)\n",
    "datainner.to_csv(\"datainner_test.csv\")\n",
    "dataouter.to_csv(\"dataouter_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"Problem_C_Data_Wordle_predict.xlsx\")\n",
    "data=data.sort_values(by=\"Date\")\n",
    "data=data.reset_index().drop(columns=\"index\")\n",
    "possible_words=data[\"Word\"].to_csv(\"data/possible_words.txt\",header=False,index=False)\n",
    "resultall=[]\n",
    "for i in optimalstart:\n",
    "    first_guess=i\n",
    "    results, decision_map = simulate_games(\n",
    "            first_guess=first_guess,\n",
    "            priors=get_true_wordle_prior(),\n",
    "            optimize_for_uniform_distribution=True,results_file=\"test.json\",next_guess_map_file=\"test2.json\",\n",
    "            # shuffle=True,\n",
    "            # brute_force_optimize=True,\n",
    "            hard_mode=True\n",
    "        )\n",
    "    resultall.append(results)\n",
    "datainner,dataouter=dataprocess(resultall,data)\n",
    "datainner.to_csv(\"datainner_pre.csv\")\n",
    "dataouter.to_csv(\"dataouter_pre.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}