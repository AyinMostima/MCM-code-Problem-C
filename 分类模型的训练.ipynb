{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入数据集预处理、特征工程和模型训练所需的库\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "trainDFraw=pd.read_csv(\".\\\\dataset\\\\DB\\\\DBPEDIA_test.csv\")\n",
    "trainDF = pandas.DataFrame()\n",
    "trainDF[\"text\"]=trainDFraw.text\n",
    "trainDF['label'] = trainDFraw.l1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#将数据集分为训练集和验证集\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
    "\n",
    "# label编码为目标变量\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#加载预先训练好的词嵌入向量\n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('H:/DATA/wiki-news-300d-1M.vec',encoding='utf-8')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#创建一个分词器\n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(trainDF['text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "#将文本转换为分词序列，并填充它们保证得到相同长度的向量\n",
    "train_seq_x = pad_sequences(token.texts_to_sequences(train_x), maxlen=200)\n",
    "valid_seq_x = pad_sequences(token.texts_to_sequences(valid_x), maxlen=200)\n",
    "\n",
    "#创建分词嵌入映射\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, LSTM, Embedding,Conv2D,Bidirectional,MaxPool2D,Reshape\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer,tokenizer_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import json\n",
    "import os\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 200, 300)          67998900  \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 200, 300)          0         \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 200, 100)         320800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 200, 100)          0         \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 200, 100, 1)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 198, 98, 64)       640       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 99, 49, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 99, 49, 64)        0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 310464)            0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 9)                 2794185   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,114,525\n",
      "Trainable params: 3,115,625\n",
      "Non-trainable params: 67,998,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "vocab_size = len(word_index)\n",
    "max_len = 200\n",
    "rnn_units = 100\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1,embedding_dim,input_length=max_len,weights=[embedding_matrix], trainable=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(rnn_units,return_sequences=True),merge_mode='sum'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Reshape((-1,rnn_units,1)))\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(9,activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adadelta',metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1425/1425 [==============================] - 736s 514ms/step - loss: 1.6089 - accuracy: 0.5134 - val_loss: 1.4923 - val_accuracy: 0.5132\n",
      "Epoch 2/10\n",
      "1425/1425 [==============================] - 616s 432ms/step - loss: 1.4375 - accuracy: 0.5197 - val_loss: 1.4513 - val_accuracy: 0.5132\n",
      "Epoch 3/10\n",
      "1425/1425 [==============================] - 507s 356ms/step - loss: 1.4103 - accuracy: 0.5197 - val_loss: 1.4320 - val_accuracy: 0.5132\n",
      "Epoch 4/10\n",
      "1425/1425 [==============================] - 510s 358ms/step - loss: 1.2777 - accuracy: 0.5505 - val_loss: 1.2677 - val_accuracy: 0.5745\n",
      "Epoch 8/10\n",
      "1425/1425 [==============================] - 527s 370ms/step - loss: 1.2207 - accuracy: 0.5795 - val_loss: 1.2023 - val_accuracy: 0.5931\n",
      "Epoch 9/10\n",
      "1425/1425 [==============================] - 520s 365ms/step - loss: 1.1583 - accuracy: 0.6001 - val_loss: 1.1357 - val_accuracy: 0.6110\n",
      "Epoch 10/10\n",
      "1425/1425 [==============================] - 686s 481ms/step - loss: 1.0991 - accuracy: 0.6178 - val_loss: 1.0779 - val_accuracy: 0.6372\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x19e21338550>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "save_dir = './saved_model'\n",
    "save_fname = os.path.join(save_dir, \"主题分析.h5\")\n",
    "callbacks = [ModelCheckpoint(filepath=save_fname, monitor='loss', save_best_only=True)]\n",
    "model.fit(train_seq_x,train_y,epochs=epochs,validation_data=(valid_seq_x,valid_y),callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}